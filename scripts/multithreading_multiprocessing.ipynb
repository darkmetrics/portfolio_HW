{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема 6: многопоточность (multithreading) и многопроцессность (multiprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Хорошая статья, картинка оттуда.](https://medium.com/contentsquare-engineering-blog/multithreading-vs-multiprocessing-in-python-ece023ad55a)\n",
    "\n",
    "![Многопоточность и многопроцессность](https://miro.medium.com/max/1250/1*2zTp9ga9egrWu7GMhLK-nA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Набор полезных ссылок:\n",
    "* [Пример из документации - ProcessThreadExecutor, там же мультипроцессинг](https://docs.python.org/3/library/concurrent.futures.html)\n",
    "* [Альтернативная документация по мультипроцессингу](https://docs.python.org/3/library/multiprocessing.html)\n",
    "* [То же самое, но более простыми словами](https://medium.com/contentsquare-engineering-blog/multithreading-vs-multiprocessing-in-python-ece023ad55a)\n",
    "* [Красивый продвинутый пример](https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python)\n",
    "* [Туториал, объясняется похуже, рассказно про Queue](https://python-scripts.com/threading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про многопоточность: \n",
    " * **Процесс** - экземпляр запущенной программы с собственной памятью, он есть в памяти компа и в Task Manager. Внутри процесса есть подпроцессы - треды. Поток - способ выполнения процесса, отдельное исполняемое задание внутри него. Потоки внутри одного процесса могут иметь общую память. \n",
    "  * Можно разбить один процесс на несколько потоков (треды), если эти потоки сами по себе занимают много времени и параллельно должны выполняться другие. Например, функция ждёт ответа от сайта. В этом случае, если мы ждём ответа от нескольких сайтов, мы запустим тред для первого сайта, потом приостановим его, запустим тред для второго, приостановим, вернёмся к первому и так далее. То есть как бы одновременный запуск по чуть-чуть всех тредов, хотя они не исполняются параллельно и процесс работает только на одном ядре, в отличие от мультипроцессинга.\n",
    "  * Отсюда вывод: если попробовать разбить на треды сложное вычислительное задание, которое загружает процессор, выйдет только хуже, чем если бы мы вообще этого не делали.\n",
    " * GIL. Lock - механизм синхронизации разных потоков. Если один поток пишет в память что-то, а другой это что-то читает, то нужен некоторый механизм, который гарантирует, что сперва всё будет записано, а потом прочтено; и механизм Lock специально за этим - он заставляет ждать отдельные треды, если необходимо. Lock можно самому поставить в код в нужный момент и можно убрать.<br>\n",
    "**Вопрос**. Работает ли это конкурентно (то есть пока доделывается один тред, уже запустился другой)? Видимо, да.<br>\n",
    "\n",
    "Стратегии использования многопоточности $(multithreading)$:\n",
    " 1. Если есть небольшое число задач, которые мы хотим выполнять конкурентно, и они различаются между собой (то есть нельзя применить аналог map), тогда можно вручную создать отдельные треды и запустить их. Например, одновременно ждать ответ от сайта, от базы данных и ещё что-то.\n",
    " 2. Если есть набор одинаковых задач, и порядок их выполнения не важен, и у них нет общих переменных, то используем ```ThreadPoolExecutor``` (типа map).\n",
    " 3. Если есть набор одинаковых задач, и порядок их выполнения важен, то используем ```Queue```. Правда, тут уже вопрос, поможет ли это ускорить программу, или выйдет только хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стратегия 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Thread(Thread-7, started 13572)> says :I am first\n",
      "<Thread(Thread-6, started 17088)> says :I am second\n",
      "<_MainThread(MainThread, started 15552)> says :I am the last!\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def work(to_sleep, to_print):\n",
    "    time.sleep(to_sleep)\n",
    "    print('{name} says :{text}'.format(name=threading.current_thread(), text=to_print))\n",
    "    \n",
    "def main():\n",
    "    t1=Thread(target=work, args=(1, 'I am second'))\n",
    "    t2=Thread(target=work, args=(0.5, 'I am first'))\n",
    "    \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    # join - дождись, пока код в треде выполнится. Это просто способ упорядочить треды, если их порядок важен.\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    # главный тред (0.1 сек) выполнил старт, подождёт, пока выполнится первый тред\n",
    "    work(0.1, 'I am the last!')\n",
    "    \n",
    "if __name__=='__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MainThread(MainThread, started 15552)> says :I am first\n",
      "<_MainThread(MainThread, started 15552)> says :I am second\n",
      "<_MainThread(MainThread, started 15552)> says :I am the last!\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "work(0.5, 'I am first')\n",
    "work(1, 'I am second')\n",
    "work(0.1, 'I am the last!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть в первом случае мы запустили функцию на 0,5 сек, одновременно на 1 сек, в конце на 0,1 сек. Из-за переключения между тредами мы получили вдобавок 0,02 сек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема: потоки имеют общую память, если они работают с общими переменными, код может сломаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273822\n",
      "Wall time: 763 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "\n",
    "# counter глобальный, поэтому надо добавить локи\n",
    "# иначе процессор запутается, и будет неверное количество итераций\n",
    "\n",
    "def work():\n",
    "    global counter\n",
    "    for _ in range(1000000):\n",
    "        counter = counter+1\n",
    "        \n",
    "def main():\n",
    "    t1 = Thread(target=work)\n",
    "    t2 = Thread(target=work)\n",
    "    \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    \n",
    "    t1.join()\n",
    "    # join гарантирует, что принт ниже будет только после окончания \n",
    "    # выполнения функции\n",
    "    t2.join()\n",
    "    \n",
    "    print(counter)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим проблему с помощью замка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from threading import Lock\n",
    "\n",
    "counter = 0\n",
    "# для разных частей программы создаются разные экземпляры Lock\n",
    "lock = Lock()\n",
    "# если будет вторая функция work(), идентичная первой, но без lock,\n",
    "# то всё сломается, как в примере выше\n",
    "\n",
    "def work():\n",
    "    global counter\n",
    "    for _ in range(1000000):\n",
    "        lock.acquire() # загорелась красная лампочка для всех процессов\n",
    "        counter = counter+1\n",
    "        lock.release()\n",
    "        \n",
    "def main():\n",
    "    t1 = Thread(target=work)\n",
    "    t2 = Thread(target=work)\n",
    "    \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    \n",
    "    print(counter)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000000\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "work()\n",
    "work()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы добавили замки, стало, естественно, хуже, чем если бы мы тупо писали код без всяких улучшений.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стратегия 2: аналог map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расммотрим конкретный пример, когда нужно применить Multithreading в духе map: есть функция, есть набор аргументов.<br>   - ```ThreadPoolExecutor(max_workers, other args)``` создаёт набор (```pool```) процессов, которые выполняются мультитредово. Что удобно, он работает как контекстный менеджер и берёт на себя запуск и склейку тредов, это уже не надо делать вручную. ```Max_workers``` представляет собой количество тредов, которое может быть больше, чем количество ядер, поскольку на одном ядре могут выполняться несколько процессов. По умолчанию этот аргумент рассчитывается как $min(32, os.cpu\\_count() + 4)$, можно его не писать самому.<br>\n",
    " * Метод ```ThreadPoolExecutor.submit()``` создаёт отдельный тред с помощью executor для каждого сочетания функция - аргументы (future).\n",
    " * Метод ```concurrent.futures.as_completed()```  возвращает итератор, который позволяет итерироваться по нескольким futures, если их выполнение успешно закончено или прервано программой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Island - exists\n",
      "https://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\n",
      "https://en.wikipedia.org/wiki/Ocean - exists\n",
      "https://en.wikipedia.org/wiki/Shark - exists\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "# future - это объект с результатом выполнения обрабатываемой функции\n",
    "\n",
    "def get_wiki_page_existence(wiki_page_url, timeout):\n",
    "    response = requests.get(url=wiki_page_url, timeout=timeout)\n",
    "\n",
    "    page_status = \"unknown\"\n",
    "    if response.status_code == 200:\n",
    "        page_status = \"exists\"\n",
    "    elif response.status_code == 404:\n",
    "        page_status = \"does not exist\"\n",
    "\n",
    "    return wiki_page_url + \" - \" + page_status\n",
    "\n",
    "wiki_page_urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Ocean\",\n",
    "    \"https://en.wikipedia.org/wiki/Island\",\n",
    "    \"https://en.wikipedia.org/wiki/this_page_does_not_exist\",\n",
    "    \"https://en.wikipedia.org/wiki/Shark\",\n",
    "]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as exec:\n",
    "    futures = []\n",
    "    for url in wiki_page_urls:\n",
    "        futures.append(exec.submit(get_wiki_page_existence, wiki_page_url=url, timeout=5))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с обычным циклом по строкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Ocean - exists\n",
      "https://en.wikipedia.org/wiki/Island - exists\n",
      "https://en.wikipedia.org/wiki/this_page_does_not_exist - does not exist\n",
      "https://en.wikipedia.org/wiki/Shark - exists\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for url in wiki_page_urls:\n",
    "    print(get_wiki_page_existence(url, timeout=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перейдём к мультипроцессингу. Он тоже есть в модуле ```concurrent.futures```, но красивее писать его по-другому."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим пример осмысленного использования модуля ```multiprocessing``` для обработки 3 последовательностей.<br>\n",
    "Стратегии работы с мультипроцессингом аналогичны мультитредингу:\n",
    " 1. Можно определить отдельные процессы, если они различаются между собой, и запустить их параллельно.<br>\n",
    " 2. Для решения множества одинаковых задач используется ```map```. <br>\n",
    "\n",
    "В модуле используется **```Pool```**, и его метод ```map``` для обработки нескольких элементов последовательности. ```Pool``` работает через ```with() ```, как контекстный менеджер.\n",
    " * **На линуксе и в обычных интерпретаторах всё работает из одной ячейки, а для винды надо импортировать целевую функцию из отдельного модуля**\n",
    " * Число процессов Pool по умолчанию равно ```os.cpu_count()```.\n",
    " * imap_unordered() позволяет обрабатывать задачи в произвольном порядке.\n",
    " * есть ещё полезный вариант ```starmap```: он позволяет создать через ```zip``` комбинации переменных для целевой функции, когда нужно подавать на вход несколько переменных, и проитерироваться по этим кортежам как ```map```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стратегия 2. Придётся вот так (функция определена в отдельном модуле):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20731, 20983, 21031, 21121, 21347, 21649, 21481, 21727, 20879, 21401]\n",
      "main took 13.091313 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "from random import randint\n",
    "from multiprocessing import Pool\n",
    "from last_prime import last_prime\n",
    "\n",
    "def timeit(f):\n",
    "    @wraps(f)\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        r = f(*args, **kwargs)\n",
    "        print('{} took {:3f} seconds'.format(f.__name__, time.time() - start))\n",
    "        return r\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "@timeit\n",
    "def main():\n",
    "    min = 12 ** 4\n",
    "    caps = [\n",
    "        min + randint(0, 1000) for _ in range(10)\n",
    "    ]\n",
    "    with Pool() as pool:\n",
    "        last_primes = pool.imap_unordered(last_prime, caps)\n",
    "        print(list(last_primes))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравним с обычным подходом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20947, 21713, 21169, 21121, 21727, 21247, 20983, 21433, 21121, 20947]\n",
      "main took 71.051435 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "from random import randint\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def is_prime(n):\n",
    "    for i in range(2, n):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def last_prime(cap):\n",
    "    max_prime = 1\n",
    "    for i in range(cap):\n",
    "        if is_prime(i):\n",
    "            max_prime = i\n",
    "\n",
    "    return max_prime\n",
    "\n",
    "\n",
    "def timeit(f):\n",
    "    @wraps(f)\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        r = f(*args, **kwargs)\n",
    "        print('{} took {:3f} seconds'.format(f.__name__, time.time() - start))\n",
    "        return r\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "@timeit\n",
    "def main():\n",
    "    min = 12 ** 4\n",
    "    caps = [\n",
    "        min + randint(0, 1000) for _ in range(10)\n",
    "    ]\n",
    "    \n",
    "    last_primes = map(last_prime, caps)\n",
    "    print(list(last_primes))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "\n",
    "def count_symbols_in_file(filename):\n",
    "    with open(filename)as f:\n",
    "        return len(f.read())\n",
    "\n",
    "\n",
    "def timeit(f):\n",
    "    @wraps(f)\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        r = f(*args, **kwargs)\n",
    "        print('{} took {:3f} seconds'.format(f.__name__, time.time() - start))\n",
    "        return r\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "@timeit\n",
    "def main():\n",
    "    time.time()\n",
    "    files = ['1', '2', '3', '4']\n",
    "    with Pool() as p:\n",
    "        res = p.map(count_symbols_in_file, files)\n",
    "        for f, r in zip(files, res):\n",
    "            print(f, r)\n",
    "\n",
    "    # for name in files:\n",
    "    #     print(name, count_symbols_in_file(name))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
